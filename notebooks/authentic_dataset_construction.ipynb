{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1: Environment Setup & Dependencies**\n",
        "In this section, we configure the runtime environment, mount persistent storage (Google Drive), and authenticate with Hugging Face to access the required datasets."
      ],
      "metadata": {
        "id": "jYLI07ijHUQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Project Setup & Directory Initialization**\n",
        "We initialize the project structure by creating the necessary subdirectories for raw data, processed features, metadata, and model checkpoints."
      ],
      "metadata": {
        "id": "v8rVl7jrFzq1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dCNl237M_Kr"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/hindi_dfake/{raw,processed,metadata,scripts,checkpoints}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Environment Configuration**\n",
        "We mount Google Drive to ensure persistent storage and dynamically define the root paths (`ROOT_DIR`, `OUT_DIR`, etc.) to avoid hardcoding errors across different sessions."
      ],
      "metadata": {
        "id": "Zft52MN2Gr2x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4eXmEHUZ1DP",
        "outputId": "4232c0b9-70d3-4191-eddf-37df6a0a6b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive is already mounted here â†’ /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, glob\n",
        "MOUNT_PATH = \"/content/drive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/gdrive\"\n",
        "print(\"Drive is already mounted here â†’\", MOUNT_PATH)\n",
        "ROOT_DIR = f\"{MOUNT_PATH}/MyDrive/hindi_dfake\"\n",
        "OUT_DIR  = f\"{ROOT_DIR}/raw/real_clean/ivr\"\n",
        "CSV_PATH = f\"{ROOT_DIR}/metadata/master_real.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Hugging Face Authentication**\n",
        "Authentication is required to download the **IndicVoices-R** and **Common Voice** datasets directly from the Hugging Face Hub."
      ],
      "metadata": {
        "id": "zjux7tS5Gu4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "3d162393b84e41b8a1c6cc279e292827",
            "a8a36cdbf3704e29ad7c012fa5eff920",
            "0e55fd890f8f467a952ecac007bd64e8",
            "edfe3d2b8b2f49e6b7d127111c86b58b",
            "a0d2d38dfb0c4d43a3aec03152ded0d1",
            "20a24eecb7894fe4a835117815d4a804",
            "181e2d098b424310a55517eeb47737f0",
            "a7b814943b454759b4f207fa95011a1e",
            "377be24bb3504334adb534383019c715",
            "44b365d69b244d75bd13f24478a5b3c8",
            "0bf243b8172045c4ac92407d1b4c7c4e",
            "b49e60e1f4f544af853d4a889d75ac80",
            "db0eee444be14017a800f361d8642c27",
            "68e8dad5df2645869c8dd6675845d9bd",
            "ce058c87323b4a1887005d4d8bca6dbb",
            "176b79b7fb60414cb0dcdbfc068c612b",
            "479258ee28ad4e88a0829e1697681250",
            "b11cb96865cf4f659853ed4a7216591c",
            "35500233ad49478c8a7a38e2c1631911",
            "f5bf6da094f947ca9054667917cb3829"
          ]
        },
        "id": "0fQKZ7FJS69O",
        "outputId": "8ab170bf-7428-4316-c982-e7d273487ccb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d162393b84e41b8a1c6cc279e292827"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itUiJxWTgGIO"
      },
      "source": [
        "# **Section 2: Authentic Dataset Construction**\n",
        "We aggregate and standardize authentic Hindi speech from diverse sourcesâ€”including **CommonVoice**, **IndicTTS** **IndicVoices**, and **FLEURS**â€”to establish a robust \"real\" baseline for our deepfake detection model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Library Dependencies**\n",
        "We install specific versions of `pandas`, `requests`, and the Hugging Face `datasets` library. Pinning these versions ensures compatibility with the data download scripts and prevents dependency conflicts."
      ],
      "metadata": {
        "id": "4iKsnIF_Jf20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qorjOtllhNIi"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq pandas==2.2.2 requests==2.32.3\n",
        "\n",
        "!pip -q install --force-reinstall --no-deps \"datasets==2.19.2\"\n",
        "\n",
        "!pip -q install pyarrow-hotfix \"fsspec[http]==2024.3.1\" --no-deps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYlvSxPVn_mt"
      },
      "source": [
        "### **2. IndicVoices-R**\n",
        "We stream 30 hours of Hindi audio from **IndicVoices-R**, filtering for valid transcripts. All files are resampled to **16kHz** and saved as WAVs with a metadata CSV."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, tqdm, hashlib, glob\n",
        "import soundfile as sf\n",
        "from datasets import load_dataset, Audio\n",
        "\n",
        "HOURS_TO_SAVE = 30\n",
        "OUT_DIR       = f\"{ROOT_DIR}/raw/real_clean/ivr\"\n",
        "CSV_PATH      = f\"{ROOT_DIR}/metadata/master_real.csv\"\n",
        "TEXT_KEY      = \"text\"\n",
        "\n",
        "# create the folders once\n",
        "os.makedirs(OUT_DIR,      exist_ok=True)\n",
        "os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "\n",
        "# --- SMART CHECK: Verify BOTH Audio and Metadata exist ---\n",
        "existing_files = glob.glob(f\"{OUT_DIR}/*.wav\")\n",
        "csv_exists = os.path.exists(CSV_PATH)\n",
        "\n",
        "if len(existing_files) > 100 and csv_exists:\n",
        "    # Only skip if we have audio AND the csv\n",
        "    print(f\"ðŸ“‚ Found {len(existing_files)} existing files and metadata CSV.\")\n",
        "    print(\"ðŸ”„ Verifying duration...\")\n",
        "    total_duration = 0\n",
        "    for f in tqdm.tqdm(existing_files, unit=\"file\"):\n",
        "        try: total_duration += sf.info(f).duration\n",
        "        except: pass\n",
        "\n",
        "    secs_done = total_duration\n",
        "    print(f\"âœ… Data and CSV already present ({secs_done/3600:.1f}h). Skipping download.\")\n",
        "\n",
        "else:\n",
        "    if len(existing_files) > 100 and not csv_exists:\n",
        "        print(\"âš ï¸ Warning: WAV files found but CSV is missing. Re-running to regenerate metadata...\")\n",
        "\n",
        "    # --- YOUR ORIGINAL CODE STARTS HERE ---\n",
        "    ds_iter = (\n",
        "        load_dataset(\"ai4bharat/indicvoices_r\", \"Hindi\",\n",
        "                    split=\"train\", streaming=True)\n",
        "        .cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "        .filter(lambda x: len(x[TEXT_KEY].strip()) > 0)\n",
        "    )\n",
        "\n",
        "    secs_cap  = HOURS_TO_SAVE * 3600\n",
        "    secs_done = 0\n",
        "\n",
        "    with open(CSV_PATH, \"w\", newline='') as csv_f, \\\n",
        "        tqdm.tqdm(total=secs_cap, unit=\"s\") as bar:\n",
        "\n",
        "        writer = csv.DictWriter(csv_f,\n",
        "                fieldnames=[\"utt_id\", \"path\", \"duration\", \"speaker_id\",\n",
        "                            \"gender\", \"text\", \"label\"])\n",
        "        writer.writeheader()\n",
        "\n",
        "        for ex in ds_iter:\n",
        "            arr, sr = ex[\"audio\"][\"array\"], ex[\"audio\"][\"sampling_rate\"]\n",
        "            dur     = len(arr) / sr\n",
        "            utt_id  = hashlib.sha1(ex[\"audio\"][\"path\"].encode()).hexdigest()[:16]\n",
        "            out_wav = f\"{OUT_DIR}/{utt_id}.wav\"\n",
        "\n",
        "            sf.write(out_wav, arr, sr)\n",
        "            writer.writerow({\n",
        "                \"utt_id\"     : utt_id,\n",
        "                \"path\"       : out_wav,\n",
        "                \"duration\"   : dur,\n",
        "                \"speaker_id\" : ex[\"speaker_id\"],\n",
        "                \"gender\"     : ex[\"gender\"],\n",
        "                \"text\"       : ex[TEXT_KEY],\n",
        "                \"label\"      : \"real\"\n",
        "            })\n",
        "\n",
        "            secs_done += dur\n",
        "            bar.update(dur)\n",
        "            if secs_done >= secs_cap:\n",
        "                break\n",
        "\n",
        "# Print final status\n",
        "print(f\"\\nSaved â‰ˆ {secs_done/3600:.1f} h of audio to Drive:\")\n",
        "print(\"  WAVs â†’\", OUT_DIR)\n",
        "print(\"  CSV  â†’\", CSV_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uHOEjYcLrrm",
        "outputId": "84177e9b-a570-4269-f4fb-c1827fa9c249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Found 11174 existing files and metadata CSV.\n",
            "ðŸ”„ Verifying duration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11174/11174 [01:56<00:00, 95.78file/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data and CSV already present (30.0h). Skipping download.\n",
            "\n",
            "Saved â‰ˆ 30.0 h of audio to Drive:\n",
            "  WAVs â†’ /content/drive/MyDrive/hindi_dfake/raw/real_clean/ivr\n",
            "  CSV  â†’ /content/drive/MyDrive/hindi_dfake/metadata/master_real.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmvUw0ur7uZ"
      },
      "source": [
        "### **3. IndicTTS-Hindi**\n",
        "We acquire approximately 10.5 hours of high-quality studio speech from the **IndicTTS-Hindi** dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "#  IndicTTS-Hindi  â†’  ~10 h studio-quality real speech\n",
        "#  â€¢ Writes WAVs to  .../raw/real_clean/indictts\n",
        "#  â€¢ Appends rows to .../metadata/master_real.csv\n",
        "# ==============================================================\n",
        "\n",
        "# ---------- imports & dirs -------------------------------------\n",
        "import os, csv, hashlib, tqdm, glob\n",
        "import soundfile as sf\n",
        "from datasets import load_dataset, Audio\n",
        "\n",
        "# ---------- paths (edit ONLY if your mount path differs) -------\n",
        "MOUNT_PATH   = \"/content/drive\"              # or \"/content/gdrive\"\n",
        "ROOT_DIR     = f\"{MOUNT_PATH}/MyDrive/hindi_dfake\"\n",
        "OUT_DIR      = f\"{ROOT_DIR}/raw/real_clean/indictts\"\n",
        "CSV_PATH     = f\"{ROOT_DIR}/metadata/master_real.csv\"\n",
        "\n",
        "# ---------- constants ------------------------------------------\n",
        "TARGET_HOURS = 10.5           # whole dataset â‰ˆ10.3 h (leave as-is)\n",
        "GENDER_MAP   = {0: \"m\", 1: \"f\", 2: \"o\"}      # fallback \"u\"\n",
        "TEXT_KEY     = \"text\"         # transcript field in IndicTTS\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "\n",
        "# --- SMART CHECK: Verify Audio exists (Note: We append to CSV, so we check WAV count only) ---\n",
        "existing_files = glob.glob(f\"{OUT_DIR}/*.wav\")\n",
        "\n",
        "if len(existing_files) > 100:\n",
        "    # SUCCESS PATH: Data exists, just print success message\n",
        "    print(f\"ðŸ“‚ Found {len(existing_files)} existing IndicTTS files.\")\n",
        "    print(\"ðŸ”„ Verifying duration...\")\n",
        "    total_duration = 0\n",
        "    for f in tqdm.tqdm(existing_files, unit=\"file\"):\n",
        "        try: total_duration += sf.info(f).duration\n",
        "        except: pass\n",
        "\n",
        "    secs_done = total_duration\n",
        "    print(f\"âœ… IndicTTS data already present ({secs_done/3600:.1f}h). Skipping download.\")\n",
        "\n",
        "else:\n",
        "    # --- ORIGINAL CODE STARTS HERE ---\n",
        "\n",
        "    # ---------- helper: write header only once ---------------------\n",
        "    need_header = not os.path.isfile(CSV_PATH)\n",
        "\n",
        "    # ---------- streaming iterator ---------------------------------\n",
        "    tts_iter = (load_dataset(\"SPRINGLab/IndicTTS-Hindi\",\n",
        "                            split=\"train\", streaming=True)\n",
        "                .cast_column(\"audio\", Audio(sampling_rate=16_000)))\n",
        "\n",
        "    secs_cap  = TARGET_HOURS * 3600\n",
        "    secs_done = 0\n",
        "\n",
        "    with open(CSV_PATH, \"a\", newline='') as csv_f, \\\n",
        "        tqdm.tqdm(total=secs_cap, unit=\"s\", desc=\"IndicTTS DL\") as bar:\n",
        "\n",
        "        writer = csv.DictWriter(csv_f,\n",
        "            fieldnames=[\"utt_id\",\"path\",\"duration\",\"speaker_id\",\n",
        "                        \"gender\",\"text\",\"label\"])\n",
        "\n",
        "        if need_header:\n",
        "            writer.writeheader()\n",
        "\n",
        "        for ex in tts_iter:\n",
        "            arr, sr = ex[\"audio\"][\"array\"], ex[\"audio\"][\"sampling_rate\"]\n",
        "            dur     = len(arr) / sr\n",
        "            utt_id  = hashlib.sha1(ex[\"audio\"][\"path\"].encode()).hexdigest()[:16]\n",
        "\n",
        "            # gender mapping (numeric â†’ letter)\n",
        "            g_val   = ex.get(\"gender\", \"u\")\n",
        "            g_letter = GENDER_MAP.get(g_val, \"u\")\n",
        "\n",
        "            out_wav = f\"{OUT_DIR}/{utt_id}.wav\"\n",
        "            sf.write(out_wav, arr, sr)\n",
        "\n",
        "            writer.writerow({\n",
        "                \"utt_id\"    : utt_id,\n",
        "                \"path\"      : out_wav,\n",
        "                \"duration\"  : dur,\n",
        "                \"speaker_id\": f\"{g_letter}_{utt_id[:4]}\",\n",
        "                \"gender\"    : g_letter,\n",
        "                \"text\"      : ex[TEXT_KEY],\n",
        "                \"label\"     : \"real\"\n",
        "            })\n",
        "\n",
        "            secs_done += dur\n",
        "            bar.update(dur)\n",
        "            if secs_done >= secs_cap:\n",
        "                break\n",
        "\n",
        "# Print final status\n",
        "print(f\"\\nâœ“ IndicTTS download finished â€” {secs_done/3600:.2f} h saved to {OUT_DIR}\")\n",
        "print(\"  Metadata appended to â†’\", CSV_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-GydRsdRckC",
        "outputId": "a3de51db-b350-4ff3-a904-b51d1aa921af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Found 4703 existing IndicTTS files.\n",
            "ðŸ”„ Verifying duration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4703/4703 [01:50<00:00, 42.57file/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… IndicTTS data already present (10.5h). Skipping download.\n",
            "\n",
            "âœ“ IndicTTS download finished â€” 10.50 h saved to /content/drive/MyDrive/hindi_dfake/raw/real_clean/indictts\n",
            "  Metadata appended to â†’ /content/drive/MyDrive/hindi_dfake/metadata/master_real.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRdRjYYltH5v"
      },
      "source": [
        "### **4. Common Voice**\n",
        "We acquire 15 hours of validated Hindi speech from **Mozilla Common Voice**, filtering for quality, duration, and community votes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "cc12168399da4f299efb968a8fa0bc28",
            "79d9779517fc4416a4c0fa51f6919768",
            "0cf40185e2674d05a19f7f750104132f",
            "c91de05c3b52479faa7b7eabc9901c85",
            "858a97fc493440a29c375764b67c33e5",
            "c32a8dff31ea4d318cc083914fefe3fb",
            "c86a060e02df420fb411bf5d97dcfb33",
            "25286a8d41204a8798ada0e1a1dbd95c",
            "fcb395ca278149eb9efcdbc21dc144d2",
            "16ab0dae48614bdfafa562a0a8a2cc81",
            "a41efdf20a034be2a044b5b8466c21a2",
            "e2ed8693e1fd4206a6a4de8273a21e3b",
            "117d66115fca46b9967a75c58677a350",
            "c3a87b6600b6436b90fc0fc87101a646",
            "04304b7ed7c44ce5a52e48d787997498",
            "08fcb602c4424592ac5bfb2177a3a972",
            "6b37645f444f46a59d2ae807343356a7",
            "4b04c8cb52bc41d2a1d2369f7b65cb25",
            "5184a746faff44c4b0a022b6e089be3a",
            "a273bc33103a418f861503928aef6b4d",
            "b18155474a5e408581c72070515ca6d8",
            "66b757bad59748c0800f97b4cdca3452",
            "1fe786bedcd84863844596a0f99889c6",
            "d678adda36f541e9b943eeba8249fca1",
            "9a5cbc7310384663a6462446a227e200",
            "429a3f84d3f24ca0b8b3835268600278",
            "75bf74ac22e94c45a3190e68a1a8ff32",
            "f0de120fa95c41fdb76577dd51ce9935",
            "644b2558aef04bb6b199223e0614cfa7",
            "097b625fd27648e58a4c937213413930",
            "ecf3741bc3ea48e4962bb8b087872bc0",
            "dbd79183e53f40e3a72342d71d2ca37f",
            "5cb81716d4ee42f8838a61f3036a25d6",
            "efdeb5d9e44d441f960aa6c734258826",
            "299c7972bc29491baba87a0351c7f2ab",
            "1133177f40e9417bbec0c5619b81018b",
            "e601abc2549942d2893c9ee783a346fc",
            "65bfdd1f612c40269d4842ea31ed5f31",
            "ce2fe54e6e994832b6dbe421c1b883ba",
            "5a053b5dd05848d0b2628b621f9e2271",
            "95fab911b4ad4e43949ba1e9efb0f041",
            "6015ba72721c4f59964a825b043e6cdd",
            "d9e5c0c90d734d61abdb50656e495ede",
            "348b50c9614d41b08dea4c92a8ebcfd4"
          ]
        },
        "id": "3LCLIZGi1RH5",
        "outputId": "19c4e689-23be-4919-9a08-eba6aa5e3d76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/load.py:1491: FutureWarning: The repository for mozilla-foundation/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_17_0\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc12168399da4f299efb968a8fa0bc28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2ed8693e1fd4206a6a4de8273a21e3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/12.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe786bedcd84863844596a0f99889c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.92k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efdeb5d9e44d441f960aa6c734258826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CommonVoice DL:   0%|          | 0/54000 [00:00<?, ?s/s]\n",
            "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
            "Reading metadata...: 1it [00:00,  2.49it/s]\u001b[A\n",
            "Reading metadata...: 10329it [00:00, 18452.01it/s]\n",
            "CommonVoice DL:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45447.37199999915/54000 [03:38<00:41, 208.03s/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Common Voice download finished â€” 12.62 h saved to /content/drive/MyDrive/hindi_dfake/raw/real_clean/commonvoice\n",
            "  Metadata appended to â†’ /content/drive/MyDrive/hindi_dfake/metadata/master_real.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "CV_REPO = \"mozilla-foundation/common_voice_17_0\"   # â† change to 17_0 if you logged in\n",
        "CV_LANG = \"hi\"                                     # Hindi config name\n",
        "TOKEN_KW = {}                                      # populated only if you logged in\n",
        "# If you ran `from huggingface_hub import login; login(\"YOUR_TOKEN\")`\n",
        "# and want v17, uncomment the next line:\n",
        "# TOKEN_KW = {\"token\": True, \"trust_remote_code\": True}\n",
        "\n",
        "# â”€â”€â”€ local paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "MOUNT_PATH  = \"/content/drive\"                      # or \"/content/gdrive\"\n",
        "ROOT_DIR    = f\"{MOUNT_PATH}/MyDrive/hindi_dfake\"\n",
        "OUT_DIR     = f\"{ROOT_DIR}/raw/real_clean/commonvoice\"\n",
        "CSV_PATH    = f\"{ROOT_DIR}/metadata/master_real.csv\"\n",
        "\n",
        "# â”€â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "TARGET_HOURS = 15\n",
        "TEXT_KEY     = \"sentence\"\n",
        "MIN_UVOTES   = 1           # â‰¥1 community up-vote\n",
        "DUR_RANGE    = (1.0, 8.0)  # 1â€“8 s clips\n",
        "ENERGY_TH    = 1e-4        # discard near-silence\n",
        "GENDER_MAP   = {\"male\":\"m\",\"female\":\"f\",\"other\":\"o\"}\n",
        "\n",
        "# â”€â”€â”€ imports & setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, csv, tqdm, hashlib, numpy as np, soundfile as sf\n",
        "from datasets import load_dataset, Audio\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "need_header = not os.path.isfile(CSV_PATH)\n",
        "\n",
        "# helper: simple RMS energy\n",
        "def rms(arr): return np.sqrt(np.mean(arr.astype(np.float32)**2))\n",
        "\n",
        "# filter for duration, up-votes, energy\n",
        "def cv_filter(ex):\n",
        "    dur = ex[\"audio\"][\"array\"].shape[-1] / 16_000\n",
        "    if not (DUR_RANGE[0] <= dur <= DUR_RANGE[1]): return False\n",
        "    if ex.get(\"up_votes\",0) < MIN_UVOTES:         return False\n",
        "    if rms(ex[\"audio\"][\"array\"]) < ENERGY_TH:     return False\n",
        "    return True\n",
        "\n",
        "# streaming iterator\n",
        "cv_iter = (\n",
        "    load_dataset(CV_REPO, CV_LANG,\n",
        "                 split=\"validated\", streaming=True,\n",
        "                 **TOKEN_KW)\n",
        "    .cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "    .filter(cv_filter)\n",
        ")\n",
        "\n",
        "# â”€â”€â”€ download loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "secs_cap  = TARGET_HOURS * 3600\n",
        "secs_done = 0\n",
        "\n",
        "with open(CSV_PATH, \"a\", newline='') as csv_f, \\\n",
        "     tqdm.tqdm(total=secs_cap, unit=\"s\", desc=\"CommonVoice DL\") as bar:\n",
        "\n",
        "    writer = csv.DictWriter(csv_f,\n",
        "        fieldnames=[\"utt_id\",\"path\",\"duration\",\"speaker_id\",\n",
        "                    \"gender\",\"text\",\"label\"])\n",
        "    if need_header: writer.writeheader()\n",
        "\n",
        "    for ex in cv_iter:\n",
        "        arr = ex[\"audio\"][\"array\"]; sr = 16_000\n",
        "        dur = len(arr) / sr\n",
        "        utt_id  = hashlib.sha1(ex[\"path\"].encode()).hexdigest()[:16]\n",
        "        gender  = GENDER_MAP.get(str(ex.get(\"gender\",\"\")).lower(), \"u\")\n",
        "\n",
        "        out_wav = f\"{OUT_DIR}/{utt_id}.wav\"\n",
        "        sf.write(out_wav, arr, sr)\n",
        "\n",
        "        writer.writerow({\n",
        "            \"utt_id\"   : utt_id,\n",
        "            \"path\"     : out_wav,\n",
        "            \"duration\" : dur,\n",
        "            \"speaker_id\": ex.get(\"client_id\",\"anon\"),\n",
        "            \"gender\"   : gender,\n",
        "            \"text\"     : ex[TEXT_KEY],\n",
        "            \"label\"    : \"real\"\n",
        "        })\n",
        "\n",
        "        secs_done += dur\n",
        "        bar.update(dur)\n",
        "        if secs_done >= secs_cap: break\n",
        "\n",
        "print(f\"\\nâœ“ Common Voice download finished â€” {secs_done/3600:.2f} h saved to {OUT_DIR}\")\n",
        "print(\"  Metadata appended to â†’\", CSV_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Google FLEURS**\n",
        "We acquire a supplementary test set from **Google FLEURS (Hindi)**, targeting up to 3000 clips (or maximum available) from all splits to ensure speaker diversity."
      ],
      "metadata": {
        "id": "I4tryrKEU4Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Colab one-cell: Bulk real Hindi (FLEURS hi_in) ~3000 clips ===\n",
        "# Safe: writes ONLY to new folders; does NOT modify your existing CSVs.\n",
        "\n",
        "# ---------- config ----------\n",
        "ROOT         = \"/content/drive/MyDrive/hindi_dfake\"\n",
        "OUT_DIR      = f\"{ROOT}/raw/real_clean/thirdparty/fleurs_hi_in\"\n",
        "CSV_OUT      = f\"{ROOT}/metadata/thirdparty_real_test.fleurs.csv\"\n",
        "N_TARGET     = 3000\n",
        "RANDOM_SEED  = 1337\n",
        "DUR_RANGE_S  = (1.0, 8.0)        # keep 1â€“8s\n",
        "SOURCE_TAG   = \"google/fleurs:hi_in\"\n",
        "LICENSE_TAG  = \"CC-BY-4.0\"\n",
        "\n",
        "# ---------- setup ----------\n",
        "import os, csv, random, hashlib, numpy as np, soundfile as sf\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Drive if needed\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(Path(CSV_OUT).parent, exist_ok=True)\n",
        "\n",
        "# clean install datasets (keeps Colab pins)\n",
        "!pip -q install datasets==2.19.0 > /dev/null\n",
        "\n",
        "from datasets import load_dataset, Audio\n",
        "\n",
        "# ---------- load & filter ----------\n",
        "print(\"[load] FLEURS hi_in (train+validation+test)â€¦\")\n",
        "ds = load_dataset(\"google/fleurs\", \"hi_in\", split=\"train+validation+test\")\n",
        "ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "\n",
        "MIN_S, MAX_S = DUR_RANGE_S\n",
        "def good_ex(ex):\n",
        "    a = ex[\"audio\"][\"array\"]; sr = ex[\"audio\"][\"sampling_rate\"]\n",
        "    if a is None: return False\n",
        "    d = len(a) / float(sr)\n",
        "    return (MIN_S <= d <= MAX_S)\n",
        "\n",
        "ds = ds.filter(good_ex)\n",
        "print(f\"[info] after dur filter: {len(ds)} rows\")\n",
        "\n",
        "# ---------- prefer unique speakers first ----------\n",
        "rng = random.Random(RANDOM_SEED)\n",
        "idx_all = list(range(len(ds)))\n",
        "# build buckets by speaker if present\n",
        "spk_col = \"speaker_id\" if \"speaker_id\" in ds.column_names else None\n",
        "if spk_col:\n",
        "    from collections import defaultdict\n",
        "    by_spk = defaultdict(list)\n",
        "    for i in idx_all:\n",
        "        by_spk[str(ds[i].get(spk_col, f\"spk?\"))].append(i)\n",
        "    speakers = list(by_spk.keys())\n",
        "    rng.shuffle(speakers)\n",
        "\n",
        "    chosen_idxs = []\n",
        "    # 1) take one per speaker (unique speakers pass)\n",
        "    for s in speakers:\n",
        "        chosen_idxs.append(by_spk[s][0])\n",
        "        if len(chosen_idxs) >= N_TARGET:\n",
        "            break\n",
        "\n",
        "    # 2) backfill (allow multiple per speaker) if needed\n",
        "    if len(chosen_idxs) < N_TARGET:\n",
        "        leftovers = []\n",
        "        for s in speakers:\n",
        "            leftovers.extend(by_spk[s][1:])  # remaining clips per spk\n",
        "        rng.shuffle(leftovers)\n",
        "        need = N_TARGET - len(chosen_idxs)\n",
        "        chosen_idxs.extend(leftovers[:need])\n",
        "\n",
        "else:\n",
        "    # no speaker ids â†’ just random sample up to N_TARGET\n",
        "    rng.shuffle(idx_all)\n",
        "    chosen_idxs = idx_all[:N_TARGET]\n",
        "\n",
        "print(f\"[pick] selected {len(chosen_idxs)} clips (target={N_TARGET})\")\n",
        "\n",
        "# ---------- save WAVs + CSV (standalone) ----------\n",
        "def norm_text(ex):\n",
        "    # FLEURS has \"transcription\" and \"raw_transcription\"\n",
        "    return ex.get(\"transcription\") or ex.get(\"raw_transcription\") or \"\"\n",
        "\n",
        "def to_wav_and_row(ex, idx):\n",
        "    arr = ex[\"audio\"][\"array\"]; sr = ex[\"audio\"][\"sampling_rate\"]  # 16k after cast\n",
        "    if arr.ndim > 1:\n",
        "        arr = arr.mean(axis=1)\n",
        "    arr = np.clip(arr.astype(np.float32), -1.0, 1.0)\n",
        "    secs = round(len(arr)/float(sr), 3)\n",
        "\n",
        "    spk = str(ex.get(spk_col, f\"spk_{idx}\"))\n",
        "    # stable utt_id from original path if available, else from content hash\n",
        "    src_path = str(ex.get(\"path\", f\"fleurs_hi_in_{idx}\"))\n",
        "    uid_base = hashlib.sha1(src_path.encode(\"utf-8\")).hexdigest()[:16]\n",
        "    utt_id = f\"fleurs_hi_{uid_base}\"\n",
        "\n",
        "    out_wav = Path(OUT_DIR) / f\"{utt_id}.wav\"\n",
        "    sf.write(str(out_wav), arr, sr, subtype=\"PCM_16\")\n",
        "\n",
        "    row = {\n",
        "        \"utt_id\": utt_id,\n",
        "        \"path\": str(out_wav).replace(\"\\\\\",\"/\"),\n",
        "        \"duration\": secs,\n",
        "        \"speaker_id\": spk,\n",
        "        \"gender\": \"u\",\n",
        "        \"text\": norm_text(ex),\n",
        "        \"label\": \"real\",\n",
        "        \"source\": SOURCE_TAG,\n",
        "        \"license\": LICENSE_TAG\n",
        "    }\n",
        "    return row\n",
        "\n",
        "rows = []\n",
        "kept = 0\n",
        "seen_paths = set()\n",
        "for i in chosen_idxs:\n",
        "    ex = ds[i]\n",
        "    r = to_wav_and_row(ex, i)\n",
        "    # avoid accidental duplicate paths\n",
        "    if r[\"path\"] in seen_paths:\n",
        "        continue\n",
        "    seen_paths.add(r[\"path\"])\n",
        "    rows.append(r); kept += 1\n",
        "\n",
        "print(f\"[save] writing CSV â†’ {CSV_OUT}\")\n",
        "with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\n",
        "        \"utt_id\",\"path\",\"duration\",\"speaker_id\",\"gender\",\"text\",\"label\",\"source\",\"license\"\n",
        "    ])\n",
        "    w.writeheader()\n",
        "    w.writerows(rows)\n",
        "\n",
        "# ---------- summary ----------\n",
        "total_sec = sum(r[\"duration\"] for r in rows)\n",
        "print(\"\\n[summary]\")\n",
        "print(f\"  WAVs saved : {kept}\")\n",
        "print(f\"  Hours      : {total_sec/3600:.2f}\")\n",
        "print(f\"  Out folder : {OUT_DIR}\")\n",
        "print(f\"  CSV        : {CSV_OUT}\")\n",
        "\n",
        "# show a few examples\n",
        "from itertools import islice\n",
        "print(\"\\n[examples]\")\n",
        "for r in islice(rows, 5):\n",
        "    print(\" â€¢\", Path(r[\"path\"]).name, \"|\", r[\"speaker_id\"], \"|\", r[\"duration\"], \"s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "ea9f5cba1151447180e8ffab26190b13",
            "ece6fade8ff7429cb6252abe30866575",
            "da8f4a1dd86646d0b0e59de390671e23",
            "c2a5aad4213d4863bba3d4719e4b036e",
            "e7609b704840469f9d8b55818d16db5f",
            "e4051d9aeb32439cb182be6daac91c6c",
            "a753da673d47445b907da95956c63d28",
            "65757c2ae4f04628848249a3781688ab",
            "5aae305eb6674c0c8851144687c9b6d1",
            "c9ab8381adde4bc4a91d907494ec3e40",
            "cea26900038c427ba18dbfadd9dad34d"
          ]
        },
        "id": "Dc9cRjb8TfG6",
        "outputId": "033e346d-4dfd-4f1d-fdea-ad9487b556df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load] FLEURS hi_in (train+validation+test)â€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/datasets/load.py:1486: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2777 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea9f5cba1151447180e8ffab26190b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] after dur filter: 604 rows\n",
            "[pick] selected 604 clips (target=3000)\n",
            "[save] writing CSV â†’ /content/drive/MyDrive/hindi_dfake/metadata/thirdparty_real_test.fleurs.csv\n",
            "\n",
            "[summary]\n",
            "  WAVs saved : 604\n",
            "  Hours      : 1.10\n",
            "  Out folder : /content/drive/MyDrive/hindi_dfake/raw/real_clean/thirdparty/fleurs_hi_in\n",
            "  CSV        : /content/drive/MyDrive/hindi_dfake/metadata/thirdparty_real_test.fleurs.csv\n",
            "\n",
            "[examples]\n",
            " â€¢ fleurs_hi_8b63ce7acd912273.wav | spk_354 | 7.56 s\n",
            " â€¢ fleurs_hi_6c47be90259fefd1.wav | spk_36 | 7.68 s\n",
            " â€¢ fleurs_hi_cb0357a131aedb4f.wav | spk_275 | 6.54 s\n",
            " â€¢ fleurs_hi_9f5518aed01136d1.wav | spk_284 | 6.18 s\n",
            " â€¢ fleurs_hi_f973483f16007db9.wav | spk_255 | 5.76 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. FLEURS Audit & Test Set Generation**\n",
        "We audit the downloaded FLEURS data to verify file integrity and generate the final `test_real.csv` manifest used for model evaluation."
      ],
      "metadata": {
        "id": "RWC8yuT-VYFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === FLEURS audit + build a dedicated test-real CSV (FLEURS-only for now) ===\n",
        "\n",
        "import os, pandas as pd, soundfile as sf\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT      = \"/content/drive/MyDrive/hindi_dfake\"\n",
        "FLEURS_CSV= f\"{ROOT}/metadata/thirdparty_real_test.fleurs.csv\"   # from your earlier one-cell\n",
        "TEST_REAL = f\"{ROOT}/metadata/test_real.csv\"                      # dedicated CSV weâ€™ll build/refresh\n",
        "REPORT_MISS = True                                                # log missing files if any\n",
        "\n",
        "assert os.path.exists(os.path.dirname(TEST_REAL)), \"metadata folder not found\"\n",
        "\n",
        "if not os.path.isfile(FLEURS_CSV):\n",
        "    raise FileNotFoundError(f\"FLEURS CSV not found at: {FLEURS_CSV}\")\n",
        "\n",
        "fleurs = pd.read_csv(FLEURS_CSV)\n",
        "\n",
        "# Optional: verify files exist and durations are plausible\n",
        "exists_mask = fleurs[\"path\"].apply(lambda p: os.path.isfile(p))\n",
        "missing = fleurs[~exists_mask]\n",
        "present = fleurs[exists_mask].copy()\n",
        "\n",
        "# If duration column exists, keep it; else compute quickly (reading headers only)\n",
        "def probe_dur(p):\n",
        "    try:\n",
        "        info = sf.info(p)\n",
        "        return float(info.duration)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "if \"duration\" not in present.columns or present[\"duration\"].isnull().any():\n",
        "    present[\"duration\"] = present[\"path\"].apply(probe_dur)\n",
        "\n",
        "# Summary\n",
        "n_total   = len(fleurs)\n",
        "n_present = len(present)\n",
        "n_missing = len(missing)\n",
        "hrs_total = (present[\"duration\"].fillna(0).sum() / 3600.0)\n",
        "\n",
        "print(\"ðŸ”Ž FLEURS audit\")\n",
        "print(f\"  rows in CSV        : {n_total}\")\n",
        "print(f\"  files present      : {n_present}\")\n",
        "print(f\"  files missing      : {n_missing}\")\n",
        "print(f\"  unique speakers    : {present['speaker_id'].astype(str).nunique()}\")\n",
        "print(f\"  hours (present)    : {hrs_total:.2f} h\")\n",
        "\n",
        "if REPORT_MISS and n_missing:\n",
        "    print(\"\\nâš ï¸ Missing files (showing up to 10):\")\n",
        "    for p in missing[\"path\"].head(10).tolist():\n",
        "        print(\"  -\", p)\n",
        "\n",
        "# Build/refresh a dedicated test-real CSV with just FLEURS for now\n",
        "cols = [\"utt_id\",\"path\",\"duration\",\"speaker_id\",\"gender\",\"text\",\"label\",\"source\",\"license\"]\n",
        "for c in cols:\n",
        "    if c not in present.columns:\n",
        "        present[c] = \"\" if c != \"duration\" else 0.0\n",
        "\n",
        "present = present[cols].copy()\n",
        "present[\"label\"] = \"real\"\n",
        "present[\"source\"] = present.get(\"source\", \"\").replace(\"\", \"google/fleurs:hi_in\")\n",
        "present[\"license\"] = present.get(\"license\", \"\").replace(\"\", \"CC-BY-4.0\")\n",
        "\n",
        "present.to_csv(TEST_REAL, index=False)\n",
        "print(f\"\\nâœ… Wrote dedicated test-real CSV (FLEURS only) â†’ {TEST_REAL}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCumwh5HrWmn",
        "outputId": "65f98e83-7a38-4454-9baa-ef4fb8cbe465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”Ž FLEURS audit\n",
            "  rows in CSV        : 604\n",
            "  files present      : 604\n",
            "  files missing      : 0\n",
            "  unique speakers    : 604\n",
            "  hours (present)    : 1.10 h\n",
            "\n",
            "âœ… Wrote dedicated test-real CSV (FLEURS only) â†’ /content/drive/MyDrive/hindi_dfake/metadata/test_real.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Train/Test Splitting (Real Speech)**\n",
        "We construct a final test set of ~3,000 samples by combining the unseen **FLEURS** data with a **speaker-disjoint** subset of Common Voice and IndicVoices-R. This ensures that the model is never tested on speakers it saw during training."
      ],
      "metadata": {
        "id": "uqxxHwR7Weja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Build ~3,000 REAL test set ===\n",
        "# - Keep existing FLEURS (~600) as-is (needs preprocessing/features later)\n",
        "# - Move the rest (~2,400) by WHOLE speakers from CV + IVR\n",
        "# - Ascending by speaker size, round-robin between sources\n",
        "# - Non-destructive: write sidecar CSVs\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/hindi_dfake\"\n",
        "MASTER_REAL = f\"{ROOT}/metadata/master_real.csv\"\n",
        "FLEURS_CSV  = f\"{ROOT}/metadata/thirdparty_real_test.fleurs.csv\"   # from your FLEURS cell\n",
        "OUT_TEST_FROM_TRAIN = f\"{ROOT}/metadata/test_real.from_train.roundrobin_least_damage.csv\"\n",
        "OUT_TEST_UNION      = f\"{ROOT}/metadata/test_real.union.csv\"\n",
        "OUT_TRAIN_AFTER     = f\"{ROOT}/metadata/train_real.after_handoff.roundrobin_least_damage.csv\"\n",
        "\n",
        "TARGET_TEST_TOTAL = 3000\n",
        "ALLOW_OVERSHOOT   = 0.05   # allow up to +5% because we move whole speakers\n",
        "SMALL_SPK_MAX_N   = 40     # cap for \"small\" speakers to avoid mega-speakers\n",
        "MIN_SPK_N         = 2      # ignore singletons if you prefer (set to 1 to allow)\n",
        "\n",
        "def detect_source(p):\n",
        "    p = str(p).lower()\n",
        "    if \"indictts\" in p: return \"IndicTTS\"\n",
        "    if \"ivr\" in p or \"indicvoices\" in p: return \"IndicVoices_R\"\n",
        "    if \"commonvoice\" in p: return \"CommonVoice\"\n",
        "    if \"fleurs\" in p: return \"FLEURS\"\n",
        "    return \"Other\"\n",
        "\n",
        "# 1) Load master + fleurs (real rows only)\n",
        "df = pd.read_csv(MASTER_REAL)\n",
        "df[\"label\"] = df[\"label\"].astype(str).str.lower()\n",
        "df[\"source\"] = df[\"path\"].apply(detect_source)\n",
        "df[\"speaker_id\"] = df[\"speaker_id\"].astype(str)\n",
        "df_real = df[df[\"label\"].eq(\"real\")].copy()\n",
        "\n",
        "fleurs = pd.DataFrame()\n",
        "if os.path.isfile(FLEURS_CSV):\n",
        "    fleurs = pd.read_csv(FLEURS_CSV)\n",
        "    fleurs[\"speaker_id\"] = fleurs[\"speaker_id\"].astype(str)\n",
        "    fleurs[\"source\"] = fleurs.get(\"source\", \"FLEURS\")\n",
        "    fleurs = fleurs.copy()\n",
        "else:\n",
        "    print(\"âš ï¸ FLEURS CSV not found; proceeding with 0 FLEURS rows.\")\n",
        "\n",
        "n_fleurs = len(fleurs)\n",
        "need_from_train = max(0, TARGET_TEST_TOTAL - n_fleurs)\n",
        "allow_max_total = int(TARGET_TEST_TOTAL * (1 + ALLOW_OVERSHOOT))\n",
        "\n",
        "print(f\"FLEURS present: {n_fleurs} rows\")\n",
        "print(f\"Target total test: {TARGET_TEST_TOTAL} â†’ need from CV+IVR: {need_from_train} rows (max allowed total={allow_max_total})\")\n",
        "\n",
        "# 2) Candidate pool = CV + IVR rows from your master (already preprocessed/features exist)\n",
        "pool = df_real[df_real[\"source\"].isin([\"CommonVoice\",\"IndicVoices_R\"])].copy()\n",
        "\n",
        "# per-speaker counts and source\n",
        "g = (pool.groupby([\"speaker_id\",\"source\"])\n",
        "          .agg(n=(\"utt_id\",\"count\"))\n",
        "          .reset_index())\n",
        "\n",
        "# filter to \"small\" speakers first to minimize disruption\n",
        "g_small = g[(g[\"n\"] >= MIN_SPK_N) & (g[\"n\"] <= SMALL_SPK_MAX_N)].copy()\n",
        "\n",
        "# build round-robin queues, smallest-first inside each source\n",
        "queues = {\n",
        "    \"CommonVoice\": deque(g_small[g_small[\"source\"].eq(\"CommonVoice\")].sort_values(\"n\")[\"speaker_id\"].tolist()),\n",
        "    \"IndicVoices_R\": deque(g_small[g_small[\"source\"].eq(\"IndicVoices_R\")].sort_values(\"n\")[\"speaker_id\"].tolist()),\n",
        "}\n",
        "\n",
        "# selection loop: alternate sources to keep mix; stop when need_from_train met\n",
        "order = [\"CommonVoice\", \"IndicVoices_R\"]\n",
        "chosen_spk = []\n",
        "chosen_rows = 0\n",
        "need = need_from_train\n",
        "\n",
        "# quick map for n per speaker\n",
        "n_per_spk = { (row[\"speaker_id\"]): int(row[\"n\"]) for _, row in g_small.iterrows() }\n",
        "\n",
        "while need > 0 and (queues[\"CommonVoice\"] or queues[\"IndicVoices_R\"]):\n",
        "    for src in order:\n",
        "        if need <= 0: break\n",
        "        if queues[src]:\n",
        "            spk = queues[src].popleft()\n",
        "            chosen_spk.append(spk)\n",
        "            chosen_rows += n_per_spk[spk]\n",
        "            need -= n_per_spk[spk]\n",
        "\n",
        "# If still under target (e.g., not enough small speakers), backfill with larger speakers (still round-robin)\n",
        "if chosen_rows < need_from_train:\n",
        "    remainder = g[(~g[\"speaker_id\"].isin(chosen_spk)) & (g[\"n\"] > SMALL_SPK_MAX_N)].copy()\n",
        "    queues_big = {\n",
        "        \"CommonVoice\": deque(remainder[remainder[\"source\"].eq(\"CommonVoice\")].sort_values(\"n\")[\"speaker_id\"].tolist()),\n",
        "        \"IndicVoices_R\": deque(remainder[remainder[\"source\"].eq(\"IndicVoices_R\")].sort_values(\"n\")[\"speaker_id\"].tolist()),\n",
        "    }\n",
        "    need2 = need_from_train - chosen_rows\n",
        "    while need2 > 0 and (queues_big[\"CommonVoice\"] or queues_big[\"IndicVoices_R\"]):\n",
        "        for src in order:\n",
        "            if need2 <= 0: break\n",
        "            if queues_big[src]:\n",
        "                spk = queues_big[src].popleft()\n",
        "                chosen_spk.append(spk)\n",
        "                chosen_rows += int(g.loc[g[\"speaker_id\"].eq(spk), \"n\"].iloc[0])\n",
        "                need2 -= int(g.loc[g[\"speaker_id\"].eq(spk), \"n\"].iloc[0])\n",
        "\n",
        "print(f\"\\nSelected speakers: {len(chosen_spk)}\")\n",
        "print(f\"Selected rows from CV+IVR: {chosen_rows}  (target from CV+IVR={need_from_train})\")\n",
        "\n",
        "# guard overshoot of TOTAL (FLEURS + moved)\n",
        "total_after = n_fleurs + chosen_rows\n",
        "if total_after > allow_max_total:\n",
        "    print(f\"âš ï¸ Overshoot: total test would be {total_after} (> {allow_max_total}). \"\n",
        "          f\"Consider lowering SMALL_SPK_MAX_N or TARGET_TEST_TOTAL.\")\n",
        "else:\n",
        "    print(f\"Projected total test (FLEURS + moved): {total_after} rows\")\n",
        "\n",
        "# 3) Build the splits\n",
        "move_mask = pool[\"speaker_id\"].isin(chosen_spk)\n",
        "df_test_from_train = pool[move_mask].copy()\n",
        "df_train_after     = pd.concat([df_real[~df_real[\"source\"].isin([\"CommonVoice\",\"IndicVoices_R\"])],  # keep IndicTTS, Other\n",
        "                               pool[~move_mask]], ignore_index=True)\n",
        "\n",
        "# union test (FLEURS + moved)\n",
        "cols = [\"utt_id\",\"path\",\"duration\",\"speaker_id\",\"gender\",\"text\",\"label\",\"source\",\"license\"]\n",
        "def ensure_cols(x):\n",
        "    for c in cols:\n",
        "        if c not in x.columns:\n",
        "            x[c] = \"\" if c != \"duration\" else 0.0\n",
        "    return x[cols].copy()\n",
        "\n",
        "df_test_from_train = ensure_cols(df_test_from_train)\n",
        "df_test_from_train[\"label\"] = \"real\"\n",
        "\n",
        "fleurs_aligned = pd.DataFrame()\n",
        "if len(fleurs):\n",
        "    fleurs_aligned = ensure_cols(fleurs.copy())\n",
        "    fleurs_aligned[\"label\"] = \"real\"\n",
        "\n",
        "df_test_union = pd.concat([fleurs_aligned, df_test_from_train], ignore_index=True)\n",
        "\n",
        "# 4) Save sidecars\n",
        "Path(OUT_TEST_FROM_TRAIN).parent.mkdir(parents=True, exist_ok=True)\n",
        "df_test_from_train.to_csv(OUT_TEST_FROM_TRAIN, index=False)\n",
        "df_test_union.to_csv(OUT_TEST_UNION, index=False)\n",
        "df_train_after.to_csv(OUT_TRAIN_AFTER, index=False)\n",
        "\n",
        "# 5) Report + safety\n",
        "def brief(name, d):\n",
        "    return {k:int(v) for k,v in d.value_counts().to_dict().items()}\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(f\"FLEURS test (already in CSV): {n_fleurs}\")\n",
        "print(f\"Moved from train â†’ test: {len(df_test_from_train)}\")\n",
        "print(f\"Total test (union): {len(df_test_union)}\")\n",
        "print(f\"Train after handoff: {len(df_train_after)}\")\n",
        "print(\"\\nBy source in moved-to-test:\", brief(\"src\", df_test_from_train[\"source\"]))\n",
        "print(\"By source in train-after  :\", brief(\"src\", df_train_after[\"source\"]))\n",
        "\n",
        "# Speaker-disjointness check (train-after vs test-union)\n",
        "assert set(df_test_union[\"speaker_id\"]).isdisjoint(set(df_train_after[\"speaker_id\"])), \"Not speaker-disjoint!\"\n",
        "print(\"\\nâœ… Speaker-disjointness verified.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyESuJzw-coA",
        "outputId": "a48e9ac9-d65d-48c3-c87a-5d3c30940c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLEURS present: 604 rows\n",
            "Target total test: 3000 â†’ need from CV+IVR: 2396 rows (max allowed total=3150)\n",
            "\n",
            "Selected speakers: 266\n",
            "Selected rows from CV+IVR: 2418  (target from CV+IVR=2396)\n",
            "Projected total test (FLEURS + moved): 3022 rows\n",
            "\n",
            "=== SUMMARY ===\n",
            "FLEURS test (already in CSV): 604\n",
            "Moved from train â†’ test: 2418\n",
            "Total test (union): 3022\n",
            "Train after handoff: 23547\n",
            "\n",
            "By source in moved-to-test: {'IndicVoices_R': 1950, 'CommonVoice': 468}\n",
            "By source in train-after  : {'CommonVoice': 9620, 'IndicVoices_R': 9224, 'IndicTTS': 4703}\n",
            "\n",
            "âœ… Speaker-disjointness verified.\n"
          ]
        }
      ]
    }
  ]
}